{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a7f3535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1\n",
      "0  PctUnemployed  0.848545\n",
      "1    PctBSorMore  0.095760\n",
      "The percent of people who are unemployed have a much larger factor to the violent crimes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#declare model and get data\n",
    "model = LinearRegression()\n",
    "data = pd.read_csv('Data/crime.csv')\n",
    "\n",
    "#receive the columns we need from data\n",
    "x = data.loc[:, ['PctUnemployed', 'PctBSorMore']]\n",
    "\n",
    "target = data['ViolentCrimesPerPop']\n",
    "\n",
    "#train  model\n",
    "trained_model = model.fit(x,target)\n",
    "\n",
    "#print results\n",
    "print(pd.DataFrame(zip(x.columns, model.coef_)))\n",
    "print(\"The percent of people who are unemployed have a much larger factor to the violent crimes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26ba1479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0         1\n",
      "0   PctUnemployed  0.210413\n",
      "1     PctBSorMore -0.063076\n",
      "2  PctPopUnderPov  0.569061\n",
      "3     PolicPerPop  0.195273\n",
      "4     Pcthomeless  0.212957\n",
      "the most influential factor is the population under poverty\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#declare model and get data\n",
    "model = LinearRegression()\n",
    "data = pd.read_csv('Data/crime.csv')\n",
    "\n",
    "#receive the columns we need from data\n",
    "x = data.loc[:, ['PctUnemployed', 'PctBSorMore', 'PctPopUnderPov', 'PolicPerPop', 'Pcthomeless']]\n",
    "\n",
    "target = data['ViolentCrimesPerPop']\n",
    "\n",
    "#train  model\n",
    "trained_model = model.fit(x,target)\n",
    "\n",
    "#print results\n",
    "print(pd.DataFrame(zip(x.columns, model.coef_)))\n",
    "print(\"the most influential factor is the population under poverty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91c4fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#declare model and get data\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "data = pd.read_csv('Data/kidney_disease.csv')\n",
    "\n",
    "#receive the columns we need from data\n",
    "x = data.loc[:, ['age', 'bp', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']]\n",
    "target = data['ckd']\n",
    "\n",
    "#train model\n",
    "trained_model = model.fit(x,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "802e14bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.9411764705882353\n",
      "f1 score is  0.9310344827586207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "#declare model and get data\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "data = pd.read_csv('Data/kidney_disease.csv')\n",
    "\n",
    "\n",
    "#receive the columns we need from data\n",
    "x = data.loc[:, ['age', 'bp', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']]\n",
    "target = data['ckd']\n",
    "\n",
    "#split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, target, test_size=0.30)\n",
    "\n",
    "#train the model\n",
    "trained_model = model.fit(X_train,y_train)\n",
    "\n",
    "#predict test data and print results\n",
    "y_predicted = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print(\"accuracy is \", accuracy)\n",
    "f1= f1_score(y_test, y_predicted)\n",
    "print(\"f1 score is \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(input_string):\n",
    "    list_of_words = input_string.split(' ')\n",
    "    dict_of_frequencies = {}\n",
    "    largestAmount = 0\n",
    "    largestWord = list_of_words[0]\n",
    "    for word in list_of_words:\n",
    "        if word in dict_of_frequencies.keys():\n",
    "            dict_of_frequencies[word] = dict_of_frequencies[word] + 1\n",
    "            if dict_of_frequencies[word] > largestAmount:\n",
    "                largestAmount = dict_of_frequencies[word]\n",
    "                largestWord = word\n",
    "        else:\n",
    "            dict_of_frequencies[word] = 1\n",
    "    return(dict_of_frequencies[largestWord]/len(list_of_words))\n",
    "    \n",
    "data = \"thing thing thing that that that that this\"\n",
    "test = get_frequency(data)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ef433b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is  0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#function to receive frequency ratio\n",
    "def get_frequency(input_string):\n",
    "    list_of_words = input_string.split(' ')\n",
    "    dict_of_frequencies = {}\n",
    "    largestAmount = 0\n",
    "    largestWord = list_of_words[0]\n",
    "    for word in list_of_words:\n",
    "        if word in dict_of_frequencies.keys():\n",
    "            dict_of_frequencies[word] = dict_of_frequencies[word] + 1\n",
    "            if dict_of_frequencies[word] > largestAmount:\n",
    "                largestAmount = dict_of_frequencies[word]\n",
    "                largestWord = word\n",
    "        else:\n",
    "            dict_of_frequencies[word] = 1\n",
    "    return(dict_of_frequencies[largestWord]/len(list_of_words))\n",
    "\n",
    "\n",
    "#receive data from file\n",
    "data = pd.read_csv('Data/email.csv')\n",
    "\n",
    "#receive the emails from file\n",
    "emails = data['email']\n",
    "\n",
    "#decalare the list we gonna use\n",
    "listOfHyperlink = []\n",
    "listOfFree = []\n",
    "listOfClick = []\n",
    "listOfBuisness = []\n",
    "listOfFrequency = []\n",
    "\n",
    "#get the data and put into their respective lists\n",
    "for i in emails:\n",
    "    words = str(i).lower()\n",
    "    list_of_words = words.split(' ')\n",
    "    if 'hyperlink' in list_of_words:\n",
    "        listOfHyperlink.append(1)\n",
    "    else: \n",
    "        listOfHyperlink.append(0)\n",
    "    if 'free' in list_of_words:\n",
    "        listOfFree.append(1)\n",
    "    else: \n",
    "        listOfFree.append(0)\n",
    "    if 'hyperlink' in list_of_words:\n",
    "        listOfClick.append(1)\n",
    "    else: \n",
    "        listOfClick.append(0)\n",
    "    if 'hyperlink' in list_of_words:\n",
    "        listOfBuisness.append(1)\n",
    "    else: \n",
    "        listOfBuisness.append(0)\n",
    "    frequency = get_frequency(words)\n",
    "    listOfFrequency.append(frequency)\n",
    "    \n",
    "    \n",
    "\n",
    "#put the data into their columns\n",
    "data['hyperlink'] = listOfHyperlink\n",
    "data['free'] = listOfFree\n",
    "data['click'] = listOfClick\n",
    "data['business'] = listOfBuisness\n",
    "data['frequency'] = listOfFrequency\n",
    "\n",
    "#put the data into readable stuff for the machine\n",
    "x = data.loc[:, ['hyperlink', 'free', 'click', 'business', 'frequency']]\n",
    "\n",
    "target = data['label']\n",
    "\n",
    "#split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, target, test_size=0.30)\n",
    "\n",
    "#make the model and run it\n",
    "model = LogisticRegression()\n",
    "\n",
    "trained_model = model.fit(X_train,y_train)\n",
    "\n",
    "#predict the model with test values\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "#print the aqccuracy\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print(\"accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf14a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
